{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0f8f287d-9ee8-46f0-b486-b22dd9e1ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cfcc8-b034-4f47-876c-64c620f317ad",
   "metadata": {},
   "source": [
    "# Stock scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8135d35-3cff-49b1-b75f-a3275ec85f35",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7e56564a-295a-484b-add8-a9cbcc81e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_list():\n",
    "    \"\"\"\n",
    "    Get a list of S&P 500 company symbols by reading the Wikipedia page.\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    tables = pd.read_html(url)\n",
    "    sp500_table = tables[0]\n",
    "    sp500_symbols = sp500_table[\"Symbol\"].tolist()\n",
    "    return sp500_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac8e2a7-9f43-4c43-b277-377cfd86b807",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "610e97a9-9dfa-4acc-8e31-d15019a00c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY_ALPHAVANTAGE = '76I7ZXLX7S7BSRAX'\n",
    "API_KEY_FAM = 'NdLNkc2mzBnSVEvOgyOqB3CBGN4YBm4v'\n",
    "\n",
    "BASE_URL_FAM = 'https://financialmodelingprep.com/api/v3'\n",
    "\n",
    "REQUEST_LIMIT = 250\n",
    "req_count = 12\n",
    "YEARS = 15\n",
    "\n",
    "DATA_DIR = '../financial_data'\n",
    "\n",
    "# List of required metrics\n",
    "required_metrics = [\n",
    "    \"GrossProfit\",\n",
    "    \"Revenues\",\n",
    "    \"NetIncomeLoss\",\n",
    "    \"StockholdersEquity\",\n",
    "    \"Liabilities\",\n",
    "    \"AssetsNoncurrent\",\n",
    "    \"NetCashProvidedByUsedInOperatingActivities\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f97ffc-4dcc-4b1f-a147-4c762f7c1cec",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5f16e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAM_free_access = [\n",
    "    'AAPL', 'TSLA', 'AMZN', 'MSFT', 'NVDA', 'GOOGL', 'META', 'NFLX', 'JPM', 'V', 'BAC', 'AMD', 'PYPL', 'DIS', 'T', 'PFE', 'COST', 'INTC', 'KO', 'TGT', 'NKE', 'SPY', 'BA', 'BABA', 'XOM', 'WMT', 'GE', 'CSCO', 'VZ', 'JNJ', 'CVX', 'PLTR', 'SQ', 'SHOP', 'SBUX', 'SOFI', 'HOOD', 'RBLX', 'SNAP', 'UBER', 'FDX', 'ABBV', 'ETSY', 'MRNA', 'LMT', 'GM', 'F', 'RIVN', 'LCID', 'CCL', 'DAL', 'UAL', 'AAL', 'TSM', 'SONY', 'ET', 'NOK', 'MRO', 'COIN', 'SIRI', 'RIOT', 'CPRX', 'VWO', 'SPYG', 'ROKU', 'VIAC', 'ATVI', 'BIDU', 'DOCU', 'ZM', 'PINS', 'TLRY', 'WBA', 'MGM', 'NIO', 'C', 'GS', 'WFC', 'ADBE', 'PEP', 'UNH', 'CARR', 'FUBO', 'HCA', 'TWTR', 'BILI', 'RKT'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ff5bd9a2-8121-40b7-88f7-a9a47e5294f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp500_tickers.csv already exists, therefore import it.\n",
      "data_progress_sp500.csv already exists, therefore import it.\n"
     ]
    }
   ],
   "source": [
    "# Create .csv files to keep track of the company data that I got\n",
    "if not os.path.exists(\"sp500_tickers.csv\"):\n",
    "    sp500_list = get_sp500_list()\n",
    "    df_sp500 = pd.DataFrame(sp500_list)\n",
    "    df_sp500.to_csv(\"sp500_tickers.csv\", index=False)\n",
    "else:\n",
    "    print(\"sp500_tickers.csv already exists, therefore import it.\")\n",
    "    df_sp500 = pd.read_csv(\"sp500_tickers.csv\")\n",
    "\n",
    "if not os.path.exists(\"data_progress_sp500.csv\"):\n",
    "    df_progress = pd.DataFrame(columns=['ticker', 'income_done', 'balance_done', 'cashflow_done'])\n",
    "    df_progress['ticker'] = sp500_list\n",
    "    df_progress['income_done'] = False\n",
    "    df_progress['balance_done'] = False\n",
    "    df_progress['cashflow_done'] = False\n",
    "    df_progress.set_index('ticker', inplace=True)\n",
    "    df_progress.to_csv(\"data_progress_sp500.csv\")\n",
    "    df_data_progress = df_progress\n",
    "else: \n",
    "    print(\"data_progress_sp500.csv already exists, therefore import it.\")\n",
    "    df_data_progress_sp500 = pd.read_csv(\"data_progress_sp500.csv\", index_col='ticker')\n",
    "\n",
    "if not os.path.exists(\"data_progress_free.csv\"):\n",
    "    df_progress = pd.DataFrame(columns=['ticker', 'income_done', 'balance_done', 'cashflow_done'])\n",
    "    df_progress['ticker'] = FAM_free_access\n",
    "    df_progress['income_done'] = False\n",
    "    df_progress['balance_done'] = False\n",
    "    df_progress['cashflow_done'] = False\n",
    "    df_progress.set_index('ticker', inplace=True)\n",
    "    df_progress.to_csv(\"data_progress_free.csv\")\n",
    "    df_data_progress_free = df_progress\n",
    "else: \n",
    "    print(\"data_progress_free.csv already exists, therefore import it.\")\n",
    "    df_data_progress_free = pd.read_csv(\"data_progress_free.csv\", index_col='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "844eb560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        income_done  balance_done  cashflow_done\n",
      "ticker                                          \n",
      "AAPL          False         False          False\n",
      "TSLA          False         False          False\n",
      "AMZN          False         False          False\n",
      "MSFT          False         False          False\n",
      "NVDA          False         False          False\n",
      "...             ...           ...            ...\n",
      "FUBO          False         False          False\n",
      "HCA           False         False          False\n",
      "TWTR          False         False          False\n",
      "BILI          False         False          False\n",
      "RKT           False         False          False\n",
      "\n",
      "[87 rows x 3 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87 entries, AAPL to RKT\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   income_done    87 non-null     bool \n",
      " 1   balance_done   87 non-null     bool \n",
      " 2   cashflow_done  87 non-null     bool \n",
      "dtypes: bool(3)\n",
      "memory usage: 957.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_data_progress_free)\n",
    "print(df_data_progress_free.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2b9c18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_tickers = df_data_progress_free.index.tolist()\n",
    "\n",
    "# check if the available tickers is in the S&P500 list\n",
    "for ticker in FAM_free_access:\n",
    "    if ticker not in list_tickers:\n",
    "        # print(f\"{ticker} is not in the s&p500 list\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_income_cols = ['reportedCurrency', 'cik', 'fillingDate', 'acceptedDate', 'calendarYear', 'link', 'finalLink', 'eps', 'epsdiluted', 'weightedAverageShsOut', 'weightedAverageShsOutDil', 'grossProfitRatio', 'ebitdaratio', 'operatingIncomeRatio', 'incomeBeforeTaxRatio']\n",
    "\n",
    "drop_balance_columns = ['reportedCurrency', 'cik', 'fillingDate', 'acceptedDate', 'link', 'calendarYear', 'finalLink', 'commonStockSharesOutstanding']\n",
    "\n",
    "drop_cashflow_columns = ['reportedCurrency', 'cik', 'fillingDate', 'acceptedDate', 'link', 'calendarYear', 'finalLink']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = 0\n",
    "\n",
    "# loop through the tickers and get their income, balance and cashflow statements\n",
    "for ticker in list_tickers:\n",
    "    \n",
    "    # Ensure the correct amount of API calls\n",
    "    if not ((REQUEST_LIMIT - req_count) > 2):\n",
    "        print(f\"Request limit reached, curr count: {req_count}\")\n",
    "        break\n",
    "\n",
    "    row = df_data_progress_free.loc[ticker]\n",
    "\n",
    "    ### INCOME STATEMENT ###\n",
    "    if not row['income_done']:\n",
    "        # do test of 2 loops\n",
    "        if count == 1: break\n",
    "\n",
    "        print(f\"Getting income statement for {ticker}...\")\n",
    "        url = f\"{BASE_URL_FAM}/income-statement/{ticker}?period=annual&limit={YEARS}&apikey={API_KEY_FAM}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            req_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed for {ticker}: {e}\")\n",
    "            break\n",
    "\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching {ticker}: {response.text}\")\n",
    "            break\n",
    "\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                df = df[income_cols]\n",
    "                df.to_csv(f\"{DATA_DIR}/{ticker}_income.csv\", index=False)\n",
    "                df_data_progress_free.loc[ticker, 'income_done'] = True\n",
    "                print(f\"Income downloaded for {ticker}\")\n",
    "            else:\n",
    "                print(f\"No data returned for {ticker}\")\n",
    "        else:\n",
    "            print(f\"Failed to get income for {ticker}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "        # break for testing\n",
    "        print()\n",
    "        count += 1 \n",
    "    break\n",
    "\n",
    "    ### BALANCE STATEMENT ###\n",
    "    if not row['balance_done']:\n",
    "        print(f\"Getting balance statement for {ticker}...\")\n",
    "        url = f\"{BASE_URL_FAM}/balance-sheet-statement/{ticker}?limit={YEARS}&apikey={API_KEY_FAM}\"\n",
    "        response = requests.get(url)\n",
    "        req_count += 1\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                pd.DataFrame(data).to_csv(f\"{DATA_DIR}/{ticker}_balance.csv\", index=False)\n",
    "                df_data_progress_free.loc[ticker, 'balance_done'] = True\n",
    "                print(f\"Balance sheet downloaded for {ticker}\")\n",
    "            else:\n",
    "                print(f\"No data returned for {ticker}\")\n",
    "        else:\n",
    "            print(f\"Failed to get balance sheet for {ticker}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "    ### CASHFLOW STATEMENT ###\n",
    "    if not row['cashflow_done']:\n",
    "        print(f\"Getting Cash flow statement for {ticker}...\")\n",
    "        url = f\"{BASE_URL_FAM}/cash-flow-statement/{ticker}?limit={YEARS}&apikey={API_KEY_FAM}\"\n",
    "        response = requests.get(url)\n",
    "        req_count += 1\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                pd.DataFrame(data).to_csv(f\"{DATA_DIR}/{ticker}_cashflow.csv\", index=False)\n",
    "                df_data_progress_free.loc[ticker, 'cashflow_done'] = True\n",
    "                print(f\"Cash flow downloaded for {ticker}\")\n",
    "            else:\n",
    "                print(f\"No data returned for {ticker}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch cash flow for {ticker}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    print()\n",
    "    count += 1 \n",
    "        \n",
    "df_data_progress_free.to_csv(\"data_progress_free.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4c7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d4fef64",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fe786",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dac19d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
